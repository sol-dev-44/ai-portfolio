# backend/requirements.txt
# Full dependencies for main.py + agent_langchain.py + lsat_service.py

# FastAPI + Server
fastapi>=0.109.0
uvicorn[standard]>=0.27.0
pydantic>=2.0.0
python-dotenv>=1.0.0

# Tokenizers (for existing tokenizer endpoints)
tiktoken>=0.5.0

# ML Models (for generation visualization)
torch>=2.0.0
transformers>=4.35.0

# LangChain ecosystem (for local agent)
langchain>=0.1.0
langchain-community>=0.0.20

# Data Fetching
datasets>=2.14.0

# HTTP Client (for LSAT service Claude API calls)
httpx>=0.25.0

# =============================================================================
# SETUP NOTES
# =============================================================================
# 
# 1. For LOCAL development with GPU:
#    pip install -r requirements.txt
#
# 2. For Railway/production (CPU only, smaller footprint):
#    Consider using torch-cpu or excluding heavy models
#
# 3. For Ollama (local LLM):
#    brew install ollama  (macOS)
#    ollama serve &
#    ollama pull llama3
#
# 4. The agent has TWO backends:
#    - Claude: Uses ANTHROPIC_API_KEY via Next.js (no Python deps)
#    - LangChain: Uses Ollama locally (requires langchain + ollama running)
#
# 5. LSAT Service:
#    - Run standalone: uvicorn lsat_service:app --port 8001
#    - Or integrate endpoints into main.py
#    - Uses httpx for async Claude API streaming
# =============================================================================